Nodes represent actions
Edge  represents flow of data

3 Key types of nodes  for creating agents using LangGraph

  LLMNode: It represents LLM which is used (Ex: GPT-4o)
  TooNode :  This node is responsible for triggering external actions
             such as calling an API or executing function
  DecsionNode: This node helps the agent decide
               the next steps based on the output from LLM or tool node

Lets create basic Q&A Agent
  Following are the key components in our Agent
    Accept user input  
    Use LLM Intelligence to  generate ie Understand the question and generate response 
    Trigger the tool nodes when needed (Ex: Fetching weather information of stock info)
    Respond back to user with detailed answer.

Generate Graph
   InputNode
   LLMNode
   ToolNode
   OutputNode



Sample AI agent

from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, MessagesState, START, END
from dotenv import load_dotenv
import os

# Initialize the LLM (using OpenAI in this example)
api_key = os.getenv("OPENAI_API_KEY")
model = ChatOpenAI(model="gpt-4o-mini", api_key=api_key)

# Function to handle the user query and call the LLM
def call_llm(state: MessagesState):
    messages = state["messages"]
    response = model.invoke(messages[-1].content)
    return {"messages": [response]}

# Define the graph
workflow = StateGraph(MessagesState)

# Add the node to call the LLM
workflow.add_node("call_llm", call_llm)

# Define the edges (start -> LLM -> end)
workflow.add_edge(START, "call_llm")
workflow.add_edge("call_llm", END)

# Compile the workflow
app = workflow.compile()

# Example input message from the user
input_message = {    
    "messages": [("human", "What is the capital of India?")]
}

# Run the workflow
for chunk in app.stream(input_message, stream_mode="values"):
    chunk["messages"][-1].pretty_print()
